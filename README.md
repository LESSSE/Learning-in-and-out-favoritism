# Learning-in-and-out-favoritism

#Model

1. Let us consider a population of N agents
2. Each agent belong to one of M sets or groups
3. Agents interact through 2-player games of cooperation
4. A strategy is defined by a pair (p,q) where: 
    1. p denotes the probability to cooperate with an agent of the same set
    2. q denotes the probability to cooperate with someone of another set
5. All individuals may potentially interact ith all other individuals (well-mixed population), yet with a bias.
6. Let us define alpha_in as the rate of interaction within a group and alpha_out the rate of interaction with members of other groups. For simplicity let us assume alpha_in = 1 and alpha_out = alpha_interaction
7. Interaction



#Classes

1. Agent has one strategy and one set, can play based on same_group or not, update strategy with one 
2. Set have agents
3. Strategys
4. Interaction (3 types: PD, SH, SD)
5. Interactions 
6. Strategy_Update


